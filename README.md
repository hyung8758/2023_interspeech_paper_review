# 2023_interspeech_paper_review
- 음성과 관련된 다양한 연구들을 참고하고자 2023년도 interspeech 논문을 리뷰한다.
- 월말마다 내용을 정리하여 업로드한다. 

## 참여인원
- 양형원
- [황수림](https://github.com/surim-lab)
- [손수한](https://github.com/soohan99)

## 논문 review의 목적
- 논문 리뷰를 통해 새로운 아이디어를 follow up 하고자 한다.
- 특히 관심있는 아이디어의 경우 실적용해보면서 그 의도를 심층탐구한다.
- 이러한 아이디어를 응용하여 내가 연구하는 분야에 실적용 해본다.

## 2023 interspeech
- 홈페이지: [방문하기](https://interspeech2023.org/)
- 페이퍼 리스트: [방문하기](https://www.isca-speech.org/archive/interspeech_2023/index.html)
- abstracts: [방문하기](https://drive.google.com/file/d/1xnYB2tQdhSNQwa3txhxFJ3OyUnLpuOCT/view)

## 논문 정리 양식
- 논문에서 필요한 내용들만 추려서 간결하게 정리하고자 한다.
- 논문 리뷰는 다음의 양식을 따르며, 필요에 따라 특정 파트는 정리를 생략한다.
    1. **논문 목적** : 논문의 목적.
    2. **기존 연구** : 논문의 기존 연구들.
    3. **제안 알고리즘** : 논문에서 제안하는 방식.
    4. **실험** : 제안 방식을 기반으로 진해한 실험.
    5. **실험 분석** : 실험 결과에 대한 분석.
    6. **결론** : 최종 결론.

## 1월 페이퍼 리뷰 list up (완료)
|No.|Topic|Reviewer|
| :---: |:---|:---:|
||**Speech Recognition**||
|1|[Selective Biasing with Trie-based Contextual Adapters for Personalised Speech Recognition using Neural Transducers](https://hushed-metal-1dc.notion.site/1-Selective-Biasing-with-Trie-based-Contextual-Adapters-for-Personalised-Speech-Recognition-using-N-2ce836df5b844748a59be003901eafc8?pvs=4)|양형원|
2|[Learning When to Trust Which Teacher for Weakly Supervised ASR](https://hushed-metal-1dc.notion.site/2-Learning-When-to-Trust-Which-Teacher-for-Weakly-Supervised-ASR-Amazon-Alexa-39607b33add147a59580065f836a1190?pvs=4)|양형원|
|3|[Text-only Domain Adaptation using Unified Speech-Text Representation in Transducer](https://hushed-metal-1dc.notion.site/3-Text-only-domain-Adaptation-using-Unified-Speech-Text-Representation-in-Transducer-ByteDance-8dfb4241165343eea2666510befcbba0?pvs=4)|양형원|
|4|[Language Agnostic Data-Driven Inverse Text Normalization](https://hushed-metal-1dc.notion.site/4-Language-Agnostic-Data-Driven-Inverse-Text-Normalization-Meta-AI-a705ad4390b7453db91dc6f4238f607d?pvs=4)|양형원|
|5|[Factual Consistency Oriented Speech Recognition](https://mica-mule-3e1.notion.site/Factual-consistency-oriented-speech-recognition-Microsoft-071c5939d92241feafce7e3676534325)|손수한|
|6|[Personalization for BERT-based Discriminative Speech Recognition Rescoring](https://github.com/surim-lab/STT_paper_reiview)|황수림|
||**Speech Synthesis**|
|7|[EmoMix: Emotion Mixing via Diffusion Models for Emotional Speech Synthesis](https://hushed-metal-1dc.notion.site/6-EmoMix-Emotion-Mixing-via-Diffusion-Models-for-Emotional-Speech-Synthesis-Ping-An-Technology-047d13a07d564efbb679f959dd3608cb?pvs=4)|양형원|

## 2월 페이퍼 리뷰 list up (준비 중)